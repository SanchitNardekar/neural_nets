{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08d6b07d-5d1a-40a6-8415-34a605d98d00",
   "metadata": {},
   "source": [
    "# Build Makemore: Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d8ac1b-499f-4a90-962d-4d577a4c3532",
   "metadata": {},
   "source": [
    "## Starting code (from previous implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec57d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffa43d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n",
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "\n",
    "stoi = { ch:i+1 for i,ch in enumerate(chars) }\n",
    "stoi['.'] = 0\n",
    "itos = { i:ch for ch,i in stoi.items() }\n",
    "\n",
    "vocab_size = len(itos)\n",
    "print(stoi)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3ac5929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228146, 3]) torch.Size([228146])\n",
      "tensor([[ 0,  0,  0],\n",
      "        [ 0,  0,  5],\n",
      "        [ 0,  5, 13],\n",
      "        [ 5, 13, 13],\n",
      "        [13, 13,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0, 15],\n",
      "        [ 0, 15, 12],\n",
      "        [15, 12,  9],\n",
      "        [12,  9, 22],\n",
      "        [ 9, 22,  9],\n",
      "        [22,  9,  1]]) tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0])\n"
     ]
    }
   ],
   "source": [
    "# Build the dataset\n",
    "\n",
    "block_size = 3\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "    \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "X, Y = build_dataset(words)\n",
    "\n",
    "print(X[:12], Y[:12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2532ab0e-916b-4318-8e68-92e2576d216d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])        # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])    # 10%\n",
    "Xte, Yte = build_dataset(words[n2:])        # 10%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b64b2d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11897\n"
     ]
    }
   ],
   "source": [
    "# MLP revisited\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_embd), generator=g) # 27x10 - initialised embedding matrix\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator = g) # (10*3)x200 - hidden layer\n",
    "b1 = torch.randn(n_hidden, generator=g) # 200, hidden layer bias\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) # 200x27 - final/output layer\n",
    "b2 = torch.randn(vocab_size, generator=g) # 27 - output layer bias\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfd72923-9703-41e8-9c58-68b48aad68a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 27.8817\n",
      "  10000/ 200000: 2.8138\n",
      "  20000/ 200000: 2.5218\n",
      "  30000/ 200000: 2.7874\n",
      "  40000/ 200000: 2.0334\n",
      "  50000/ 200000: 2.6237\n",
      "  60000/ 200000: 2.3289\n",
      "  70000/ 200000: 2.0826\n",
      "  80000/ 200000: 2.2784\n",
      "  90000/ 200000: 2.2252\n",
      " 100000/ 200000: 2.0428\n",
      " 110000/ 200000: 2.6116\n",
      " 120000/ 200000: 2.0478\n",
      " 130000/ 200000: 2.7178\n",
      " 140000/ 200000: 2.3032\n",
      " 150000/ 200000: 2.2888\n",
      " 160000/ 200000: 2.0090\n",
      " 170000/ 200000: 1.8710\n",
      " 180000/ 200000: 2.1687\n",
      " 190000/ 200000: 1.8489\n"
     ]
    }
   ],
   "source": [
    "# use the same optimisation values as previously when biuilding the MLP\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors by indexing (using X values) into the appropriate vector embeddings from the initialised C matrix\n",
    "    # reshape this into a concatenation of embeddings for each context char\n",
    "    # emb.shape[0] here is the num examples in Xb and -1 tells PyTorch to \n",
    "    # infer the remaining dimension shape given it needs to be a 2D tensor \n",
    "    # and the first dimensions shape is given.\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1 # hiddne layer pre-activation\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if 1 < 100000 else 0.01 # step func for learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every 10k steps\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "\n",
    "    lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd5617de-137a-4947-b127-6c16c8f24c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11e23ce80>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1620e75-9136-429b-9a47-4210d7c56aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # disables gradient tracking for a function\n",
    "def split_loss(split):\n",
    "    \"\"\"evaluate loss for a particular split of the data\"\"\"\n",
    "    x,y = {\n",
    "        'train': (Xtr, Ytr),\n",
    "        'val': (Xdev, Ydev),\n",
    "        'test': (Xte, Yte),\n",
    "    }[split]\n",
    "\n",
    "    emb = C[x]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    h = torch.tanh(embcat @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "091429eb-6d32-4fd9-94fa-db744c2b8c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.1853060722351074\n",
      "val 2.2459235191345215\n"
     ]
    }
   ],
   "source": [
    "starting_train_loss = split_loss('train')\n",
    "starting_val_loss = split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd4a587d-a4ff-4d9f-b77c-c12f7063d5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carlah.\n",
      "qui.\n",
      "heri.\n",
      "kemy.\n",
      "khea.\n",
      "cassley.\n",
      "kenzaheen.\n",
      "den.\n",
      "archereei.\n",
      "ney.\n",
      "ken.\n",
      "chriivon.\n",
      "nege.\n",
      "dham.\n",
      "edin.\n",
      "quinthonor.\n",
      "emmaveni.\n",
      "wazthon.\n",
      "jaryxi.\n",
      "jayenni.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    out = []\n",
    "    context = [0] * block_size # intialise with all \"...\"\n",
    "\n",
    "    while True:\n",
    "        # forward pass the neural net\n",
    "        emb = C[torch.tensor([context])] # (1, block_size, n_embd)\n",
    "        h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        # calculate probabilities for all chars in vocab\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "\n",
    "        # sample from the distribution\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        #shift the context window and track the samples\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        # if we sample the '.' token - break\n",
    "        if ix == 0:\n",
    "            break\n",
    "\n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68be39a-b5bb-4c7e-bfdb-698a1ac2527b",
   "metadata": {},
   "source": [
    "## Optimising the Model Parameter Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76c3995-488f-494f-b872-7ae872947526",
   "metadata": {},
   "source": [
    "The initialisation of the network produces a loss that is much too high than we would expect. It is roughly 27 epoch 0 when it should be around 3 if we initialised the network with all 27 characters having equal probability of being selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eab7abde-c86a-4152-a249-c0ad0f4591a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2958)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_loss_at_initialisation = -torch.tensor(1/27.0).log()\n",
    "expected_loss_at_initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "110db81f-4e0d-443f-b0e7-56c21d09ca96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([7.4689e-43, 5.5211e-42, 3.7835e-44, 1.0000e+00]), tensor(99.9831))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4D example of the issue\n",
    "logits = torch.tensor([3.0, 5.0, 0.0, 100]) # The more wrong the logits are initially, the higher the loss will be\n",
    "probs = torch.softmax(logits, dim=0)\n",
    "loss = -probs[2].log() # 2 would be the y label index\n",
    "probs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1e124dfe-449e-43b5-bb91-4abb636e0db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1624, 0.5643, 0.0979, 0.1755]), tensor(2.3239))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With random logits this turns out okay most of the time since the logits are close to 0\n",
    "logits = torch.randn(4)\n",
    "probs = torch.softmax(logits, dim=0)\n",
    "loss = -probs[2].log() # 2 would be the y label index\n",
    "probs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84c18d8a-4ace-4132-81cd-e107b6675b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0527e-08, 2.1350e-13, 1.0980e-07, 1.0000e+00]), tensor(16.0246))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If logits are much higher, it's much more likely that we'll have a much higher initial loss\n",
    "# To combat this, we can initialise as a uniform distribution of 0s or 1s\n",
    "logits = torch.randn(4) * 10\n",
    "probs = torch.softmax(logits, dim=0)\n",
    "loss = -probs[2].log() # 2 would be the y label index\n",
    "probs, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e02a42-3a74-48eb-b011-5ba1a4aee477",
   "metadata": {},
   "source": [
    "When printing the logit values after the first pass of the minibatch, we get the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ffd5312e-3158-490f-af5c-9d077d8df44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11897\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator = g)\n",
    "b1 = torch.randn(n_hidden, generator=g) \n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g)\n",
    "b2 = torch.randn(vocab_size, generator=g)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae884f3f-fbb7-4830-b372-ee0a1e59dbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 27.8817\n"
     ]
    }
   ],
   "source": [
    "# use the same optimisation values as previously when building the MLP\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):#\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors by indexing (using X values) into the appropriate vector embeddings from the initialised C matrix\n",
    "    # reshape this into a concatenation of embeddings for each context char\n",
    "    # emb.shape[0] here is the num examples in Xb and -1 tells PyTorch to \n",
    "    # infer the remaining dimension shape given it needs to be a 2D tensor \n",
    "    # and the first dimensions shape is given.\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1 # hiddne layer pre-activation\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if 1 < 100000 else 0.01 # step func for learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every 10k steps\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "\n",
    "    lossi.append(loss.log10().item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad29985c-fdf5-4430-844d-b6f6347a45b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -2.3527,  36.4366, -10.7306,   5.7165,  18.6409, -11.6998,  -2.1991,\n",
      "          1.8535,  10.9996,  10.6730,  12.3507, -10.3809,   4.7243, -24.4257,\n",
      "         -8.5909,   1.9024, -12.2744, -12.4751, -23.2778,  -2.0163,  25.8767,\n",
      "         14.2108,  17.7691, -10.9204, -20.7335,   6.4560,  11.1615],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(logits[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300dc87e-cfc8-4b0b-9d13-ffae818e2a1f",
   "metadata": {},
   "source": [
    "Logit values are quite large giving us the large loss value we see. The first few passes of the training loop have to squeeze down the values of the weights to get to an acceptable value of loss, making the training inefficient.\n",
    "\n",
    "We can therefore multiply the weights and biases of W2 and b2 by a small value and 0 respectively to ensure we get a good initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4bbba1d0-6e8f-4bb3-a3dc-56c47c7c96ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11897\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator = g)\n",
    "b1 = torch.randn(n_hidden, generator=g) \n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.01 # We don't want to set weights of a NN to 0\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0 # Biases are fine to set to 0 initially\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cdd8b370-e4c5-44ea-a17a-aa39aaa95c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3221\n",
      "  10000/ 200000: 2.1900\n",
      "  20000/ 200000: 2.4196\n",
      "  30000/ 200000: 2.6067\n",
      "  40000/ 200000: 2.0601\n",
      "  50000/ 200000: 2.4988\n",
      "  60000/ 200000: 2.3902\n",
      "  70000/ 200000: 2.1344\n",
      "  80000/ 200000: 2.3369\n",
      "  90000/ 200000: 2.1299\n",
      " 100000/ 200000: 1.8329\n",
      " 110000/ 200000: 2.4014\n",
      " 120000/ 200000: 1.8664\n",
      " 130000/ 200000: 2.4811\n",
      " 140000/ 200000: 2.3314\n",
      " 150000/ 200000: 2.2080\n",
      " 160000/ 200000: 1.9675\n",
      " 170000/ 200000: 1.9001\n",
      " 180000/ 200000: 2.1143\n",
      " 190000/ 200000: 1.8791\n"
     ]
    }
   ],
   "source": [
    "# use the same optimisation values as previously when building the MLP\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):#\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors by indexing (using X values) into the appropriate vector embeddings from the initialised C matrix\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if 1 < 100000 else 0.01 # step func for learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every 10k steps\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "\n",
    "    lossi.append(loss.log10().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2f419d-175c-4bc2-9eb8-ba54cdfcbe95",
   "metadata": {},
   "source": [
    "The loss now looks much better at 0 (~3 vs ~27), and the NN is spending it's training time much more efficiently, leading to better val and test set scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9d1fea10-2f83-4a48-979f-56db92e8489d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.157895088195801\n",
      "val 2.2293787002563477\n"
     ]
    }
   ],
   "source": [
    "better_initialisation_train_loss = split_loss('train')\n",
    "better_initialisation_val_loss = split_loss('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8f10b0-8846-485e-9eb3-0dc4161a1d00",
   "metadata": {},
   "source": [
    "## Optimising for the activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "723e9f11-5e28-4d8b-98be-9b7bc7446ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11897\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator = g)\n",
    "b1 = torch.randn(n_hidden, generator=g) \n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.01 # We don't want to set weights of a NN to 0\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0 # Biases are fine to set to 0 initially\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5a08633c-1b2c-4981-97f1-0c3ac878aa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3221\n"
     ]
    }
   ],
   "source": [
    "# use the same optimisation values as previously when building the MLP\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):#\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors by indexing (using X values) into the appropriate vector embeddings from the initialised C matrix\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if 1 < 100000 else 0.01 # step func for learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every 10k steps\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "\n",
    "    lossi.append(loss.log10().item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d9372749-25db-4957-8fa4-ead461dc4fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 200]),\n",
       " tensor([[ 0.8100, -0.8997, -0.9993,  ..., -0.9097, -1.0000,  1.0000],\n",
       "         [-1.0000, -0.9571, -0.7145,  ...,  0.4898,  0.9090,  0.9937],\n",
       "         [ 0.9983, -0.3340,  1.0000,  ...,  0.9443,  0.9905,  1.0000],\n",
       "         ...,\n",
       "         [-1.0000,  0.9604, -0.1418,  ..., -0.1266,  1.0000,  1.0000],\n",
       "         [-1.0000, -0.4385, -0.8882,  ..., -0.3316,  0.9995,  1.0000],\n",
       "         [-1.0000,  0.9604, -0.1418,  ..., -0.1266,  1.0000,  1.0000]],\n",
       "        grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ac6ef10c-d811-4af4-970c-7948aca702c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6400]),\n",
       " [0.8100225329399109,\n",
       "  -0.8996701836585999,\n",
       "  -0.999309241771698,\n",
       "  0.9980825185775757,\n",
       "  -0.6508480906486511,\n",
       "  -0.6897538900375366,\n",
       "  -0.961920976638794,\n",
       "  -0.9999876022338867,\n",
       "  -0.34206923842430115,\n",
       "  0.999920666217804,\n",
       "  0.9999915957450867,\n",
       "  -0.9980642199516296,\n",
       "  0.9876819252967834,\n",
       "  0.8998492956161499,\n",
       "  0.8862372636795044,\n",
       "  0.7360543012619019,\n",
       "  -0.9959285855293274,\n",
       "  -0.981837809085846,\n",
       "  -0.9892273545265198,\n",
       "  0.9997955560684204,\n",
       "  -0.9220332503318787,\n",
       "  -0.8541553616523743,\n",
       "  0.06397326290607452,\n",
       "  0.9999996423721313,\n",
       "  0.9979971051216125,\n",
       "  -0.9949458837509155,\n",
       "  0.9996280670166016,\n",
       "  -0.9998515844345093,\n",
       "  0.6444540619850159,\n",
       "  0.7554436922073364,\n",
       "  -0.9997296929359436,\n",
       "  0.9996114373207092,\n",
       "  0.9912618398666382,\n",
       "  0.9449752569198608,\n",
       "  0.9999983310699463,\n",
       "  -0.9999998211860657,\n",
       "  0.9999754428863525,\n",
       "  -0.9999991059303284,\n",
       "  1.0,\n",
       "  -0.556519091129303,\n",
       "  0.9787917733192444,\n",
       "  -0.9885086417198181,\n",
       "  0.9983248710632324,\n",
       "  -0.9999771118164062,\n",
       "  -0.036519937217235565,\n",
       "  0.9999677538871765,\n",
       "  0.9990684986114502,\n",
       "  -0.7250180244445801,\n",
       "  -0.9920523762702942,\n",
       "  -0.9998557567596436,\n",
       "  -0.9981667995452881,\n",
       "  -0.9987424612045288,\n",
       "  -0.9999971985816956,\n",
       "  -0.9002601504325867,\n",
       "  -1.0,\n",
       "  0.9369037747383118,\n",
       "  -0.8497680425643921,\n",
       "  -0.9963060021400452,\n",
       "  -0.9943669438362122,\n",
       "  -0.930077850818634,\n",
       "  0.9993545413017273,\n",
       "  0.5702772736549377,\n",
       "  -0.18814639747142792,\n",
       "  -0.9940271377563477,\n",
       "  0.9875222444534302,\n",
       "  0.24000954627990723,\n",
       "  0.9366224408149719,\n",
       "  -0.9982050061225891,\n",
       "  -0.9999827742576599,\n",
       "  0.997356653213501,\n",
       "  0.997997522354126,\n",
       "  0.8843950033187866,\n",
       "  -0.3261958658695221,\n",
       "  -0.8462293148040771,\n",
       "  0.9521180987358093,\n",
       "  0.986286461353302,\n",
       "  0.9999999403953552,\n",
       "  0.061766453087329865,\n",
       "  0.9887017607688904,\n",
       "  0.9958049058914185,\n",
       "  0.9999606609344482,\n",
       "  0.9997110366821289,\n",
       "  -0.9999688863754272,\n",
       "  -0.9999934434890747,\n",
       "  0.9999960064888,\n",
       "  -0.9999960660934448,\n",
       "  0.9035527110099792,\n",
       "  -0.9713432788848877,\n",
       "  -0.9945881366729736,\n",
       "  -0.7770710587501526,\n",
       "  0.5586824417114258,\n",
       "  0.9999998807907104,\n",
       "  -0.999806821346283,\n",
       "  0.9999704360961914,\n",
       "  -0.999687910079956,\n",
       "  0.9993345141410828,\n",
       "  -0.9997174143791199,\n",
       "  -0.9999829530715942,\n",
       "  -0.9977675676345825,\n",
       "  -1.0,\n",
       "  -0.9977041482925415,\n",
       "  0.9996653199195862,\n",
       "  0.9783895015716553,\n",
       "  -0.9999988675117493,\n",
       "  -0.9961305260658264,\n",
       "  1.0,\n",
       "  0.9912627935409546,\n",
       "  -0.980395495891571,\n",
       "  1.0,\n",
       "  -0.999946117401123,\n",
       "  0.9999759793281555,\n",
       "  0.9812180399894714,\n",
       "  -0.9996610283851624,\n",
       "  0.9999865293502808,\n",
       "  -0.9987479448318481,\n",
       "  -1.0,\n",
       "  -0.5870449542999268,\n",
       "  -0.6761990189552307,\n",
       "  0.8443390130996704,\n",
       "  0.9899460077285767,\n",
       "  0.9999991059303284,\n",
       "  0.9998961687088013,\n",
       "  -0.8078447580337524,\n",
       "  -0.03011174313724041,\n",
       "  -0.9869007468223572,\n",
       "  -0.39575284719467163,\n",
       "  -1.0,\n",
       "  -0.9934996962547302,\n",
       "  0.9999702572822571,\n",
       "  0.6229590177536011,\n",
       "  -0.801450252532959,\n",
       "  -0.9999998807907104,\n",
       "  -0.9999948143959045,\n",
       "  0.881597101688385,\n",
       "  0.6985352039337158,\n",
       "  0.9590635895729065,\n",
       "  -0.9998769164085388,\n",
       "  -0.9998448491096497,\n",
       "  0.9467463493347168,\n",
       "  0.9936731457710266,\n",
       "  -0.9963385462760925,\n",
       "  -1.0,\n",
       "  -0.9992644786834717,\n",
       "  0.9999996423721313,\n",
       "  -0.8874372243881226,\n",
       "  0.9999810457229614,\n",
       "  0.7788860201835632,\n",
       "  0.9999997615814209,\n",
       "  0.999984085559845,\n",
       "  -0.9999938607215881,\n",
       "  -0.9998727440834045,\n",
       "  0.9999978542327881,\n",
       "  0.921228289604187,\n",
       "  0.999005138874054,\n",
       "  -0.02489868737757206,\n",
       "  -0.9494708180427551,\n",
       "  0.9998114705085754,\n",
       "  -0.23464937508106232,\n",
       "  -0.9822018146514893,\n",
       "  -0.9989956617355347,\n",
       "  0.9024651646614075,\n",
       "  0.9995178580284119,\n",
       "  0.9997413754463196,\n",
       "  0.9984540939331055,\n",
       "  0.9999995231628418,\n",
       "  0.9999933838844299,\n",
       "  0.9999788999557495,\n",
       "  0.9989426136016846,\n",
       "  -0.9533620476722717,\n",
       "  -0.9924253225326538,\n",
       "  0.9993343949317932,\n",
       "  -0.9999023079872131,\n",
       "  -0.999996542930603,\n",
       "  0.9959509372711182,\n",
       "  -0.9999775886535645,\n",
       "  -0.99789959192276,\n",
       "  -0.930158257484436,\n",
       "  0.9999384880065918,\n",
       "  0.9859923720359802,\n",
       "  0.41335612535476685,\n",
       "  0.9913343787193298,\n",
       "  -0.9888933897018433,\n",
       "  1.0,\n",
       "  -0.9996615648269653,\n",
       "  0.7882044911384583,\n",
       "  -0.8811992406845093,\n",
       "  1.0,\n",
       "  0.494822233915329,\n",
       "  -0.9999998807907104,\n",
       "  -0.9999991059303284,\n",
       "  0.9263261556625366,\n",
       "  -0.9999998211860657,\n",
       "  -0.9975093007087708,\n",
       "  -0.9927806258201599,\n",
       "  0.9999793171882629,\n",
       "  0.6177865266799927,\n",
       "  -1.0,\n",
       "  -0.9096858501434326,\n",
       "  -1.0,\n",
       "  0.999999463558197,\n",
       "  -1.0,\n",
       "  -0.9571481347084045,\n",
       "  -0.7144952416419983,\n",
       "  0.608306348323822,\n",
       "  -0.9999923706054688,\n",
       "  -0.9999361634254456,\n",
       "  0.992590069770813,\n",
       "  -0.23023267090320587,\n",
       "  -0.9952198266983032,\n",
       "  0.9999175667762756,\n",
       "  -0.1635759174823761,\n",
       "  -0.9754257798194885,\n",
       "  -0.9999455809593201,\n",
       "  0.9999546408653259,\n",
       "  -0.9152315855026245,\n",
       "  -0.9999316930770874,\n",
       "  0.9998354315757751,\n",
       "  -0.9999645948410034,\n",
       "  0.9749690890312195,\n",
       "  0.9999935030937195,\n",
       "  -1.0,\n",
       "  -0.9999347925186157,\n",
       "  -0.23398931324481964,\n",
       "  -0.8811324834823608,\n",
       "  0.999308168888092,\n",
       "  0.9999399781227112,\n",
       "  0.815850019454956,\n",
       "  -0.9805248379707336,\n",
       "  0.9999948740005493,\n",
       "  0.09357946366071701,\n",
       "  0.999998152256012,\n",
       "  0.9986162781715393,\n",
       "  -0.31729036569595337,\n",
       "  -0.999615490436554,\n",
       "  0.977964460849762,\n",
       "  -0.993132472038269,\n",
       "  -0.3045639991760254,\n",
       "  -0.9999614953994751,\n",
       "  0.4640646278858185,\n",
       "  -0.9999939799308777,\n",
       "  0.9684109091758728,\n",
       "  -0.6552897691726685,\n",
       "  0.9999061822891235,\n",
       "  -0.9693756103515625,\n",
       "  -0.9755737781524658,\n",
       "  0.581757128238678,\n",
       "  -0.0019763943273574114,\n",
       "  -0.9783424139022827,\n",
       "  0.996645450592041,\n",
       "  0.347557008266449,\n",
       "  -0.8612285852432251,\n",
       "  0.9934705495834351,\n",
       "  0.9292688369750977,\n",
       "  0.27449750900268555,\n",
       "  0.35823142528533936,\n",
       "  -0.2502475678920746,\n",
       "  -0.4245913028717041,\n",
       "  -0.2827664315700531,\n",
       "  0.990460991859436,\n",
       "  0.9999821782112122,\n",
       "  0.9995743036270142,\n",
       "  -0.41160884499549866,\n",
       "  0.9996185898780823,\n",
       "  -0.9627837538719177,\n",
       "  -0.9999964833259583,\n",
       "  -0.9961535334587097,\n",
       "  0.9999749660491943,\n",
       "  -0.419918954372406,\n",
       "  -0.999995768070221,\n",
       "  -0.9082741737365723,\n",
       "  0.9957168698310852,\n",
       "  -0.88327556848526,\n",
       "  -0.8657531142234802,\n",
       "  -0.9999595284461975,\n",
       "  -0.9996703863143921,\n",
       "  0.9959312677383423,\n",
       "  0.876748263835907,\n",
       "  -0.9999995231628418,\n",
       "  -0.24314023554325104,\n",
       "  0.9900190234184265,\n",
       "  0.9998999238014221,\n",
       "  0.9995512962341309,\n",
       "  0.8095017075538635,\n",
       "  0.9999955296516418,\n",
       "  -0.9779530167579651,\n",
       "  0.6011898517608643,\n",
       "  -0.8299564123153687,\n",
       "  -0.2544001638889313,\n",
       "  -0.7841108441352844,\n",
       "  -0.6552473306655884,\n",
       "  0.9999873638153076,\n",
       "  0.9999319911003113,\n",
       "  -0.9739892482757568,\n",
       "  -0.9996010065078735,\n",
       "  0.9935691356658936,\n",
       "  0.9264558553695679,\n",
       "  0.6537734866142273,\n",
       "  -0.999888002872467,\n",
       "  -0.9999980926513672,\n",
       "  -0.9848827719688416,\n",
       "  -0.9999999403953552,\n",
       "  0.9455536007881165,\n",
       "  -1.0,\n",
       "  -0.43477463722229004,\n",
       "  0.9960339665412903,\n",
       "  0.999993622303009,\n",
       "  -0.9999443888664246,\n",
       "  -0.9335628151893616,\n",
       "  0.9999955296516418,\n",
       "  0.9999945759773254,\n",
       "  0.9319667220115662,\n",
       "  0.999705970287323,\n",
       "  0.9779126644134521,\n",
       "  -0.9999997615814209,\n",
       "  -0.9999979734420776,\n",
       "  0.9998584389686584,\n",
       "  -0.9318667650222778,\n",
       "  -0.9997481107711792,\n",
       "  -0.9510408043861389,\n",
       "  0.9660475850105286,\n",
       "  -0.2599531412124634,\n",
       "  0.9999544620513916,\n",
       "  0.9792224168777466,\n",
       "  0.9992381930351257,\n",
       "  -0.9990394711494446,\n",
       "  1.0,\n",
       "  0.9966996908187866,\n",
       "  -0.9132043123245239,\n",
       "  0.8383743762969971,\n",
       "  -0.9955636858940125,\n",
       "  0.9999999403953552,\n",
       "  0.6927374005317688,\n",
       "  -1.0,\n",
       "  0.999942421913147,\n",
       "  -0.998464047908783,\n",
       "  -0.9998220801353455,\n",
       "  -0.9999482035636902,\n",
       "  -0.9999680519104004,\n",
       "  -0.9992222785949707,\n",
       "  -0.9932911396026611,\n",
       "  -0.9999990463256836,\n",
       "  -0.9983988404273987,\n",
       "  -1.0,\n",
       "  -0.9999499320983887,\n",
       "  0.9999954700469971,\n",
       "  0.9766961932182312,\n",
       "  -0.9806585907936096,\n",
       "  0.9999988079071045,\n",
       "  0.9987587928771973,\n",
       "  -0.9726282358169556,\n",
       "  -0.8263392448425293,\n",
       "  -0.9998685121536255,\n",
       "  -0.9999945759773254,\n",
       "  0.9999999403953552,\n",
       "  0.9993388056755066,\n",
       "  0.9996516108512878,\n",
       "  1.0,\n",
       "  -0.9970816969871521,\n",
       "  0.02247786335647106,\n",
       "  0.6257541179656982,\n",
       "  0.9999946355819702,\n",
       "  0.9067497253417969,\n",
       "  -0.9879018664360046,\n",
       "  -0.8666962385177612,\n",
       "  0.9825180768966675,\n",
       "  -0.8207035660743713,\n",
       "  -0.9972060918807983,\n",
       "  0.36264535784721375,\n",
       "  -0.9543379545211792,\n",
       "  -0.9995741248130798,\n",
       "  0.9997570514678955,\n",
       "  0.9021596312522888,\n",
       "  -0.9999995827674866,\n",
       "  -0.6650104522705078,\n",
       "  0.9999971389770508,\n",
       "  -0.9279243350028992,\n",
       "  -0.7687095999717712,\n",
       "  -0.9780287742614746,\n",
       "  -0.9752737879753113,\n",
       "  -0.9814651012420654,\n",
       "  0.9999958872795105,\n",
       "  -0.9999933838844299,\n",
       "  -0.9999985694885254,\n",
       "  -0.8322641253471375,\n",
       "  0.9999794960021973,\n",
       "  0.9998984932899475,\n",
       "  0.9564246535301208,\n",
       "  -0.7396095991134644,\n",
       "  -0.9999993443489075,\n",
       "  0.9999769926071167,\n",
       "  -0.6260095834732056,\n",
       "  0.9983258247375488,\n",
       "  0.9999971985816956,\n",
       "  0.6562151908874512,\n",
       "  -0.9567598700523376,\n",
       "  -0.9783781170845032,\n",
       "  -0.2786048650741577,\n",
       "  0.48981279134750366,\n",
       "  0.9090304374694824,\n",
       "  0.9937247037887573,\n",
       "  0.9983464479446411,\n",
       "  -0.3340475559234619,\n",
       "  0.999984085559845,\n",
       "  0.9973723888397217,\n",
       "  1.0,\n",
       "  0.9870656132698059,\n",
       "  0.9821177124977112,\n",
       "  -0.9929129481315613,\n",
       "  0.9903534054756165,\n",
       "  0.9052069783210754,\n",
       "  -0.9621332883834839,\n",
       "  0.7818785309791565,\n",
       "  0.9985976219177246,\n",
       "  0.9999998807907104,\n",
       "  -0.9028624296188354,\n",
       "  -1.0,\n",
       "  1.0,\n",
       "  -0.9733802080154419,\n",
       "  -0.9999938011169434,\n",
       "  1.0,\n",
       "  0.9957493543624878,\n",
       "  0.9054943919181824,\n",
       "  0.9920600056648254,\n",
       "  -0.9476560354232788,\n",
       "  -0.9999943971633911,\n",
       "  0.9929003715515137,\n",
       "  -0.9999613165855408,\n",
       "  0.9825389385223389,\n",
       "  0.9997782111167908,\n",
       "  0.9996485710144043,\n",
       "  -0.9996919631958008,\n",
       "  -0.9997891783714294,\n",
       "  -0.9998714327812195,\n",
       "  -0.9513139724731445,\n",
       "  -0.9999999403953552,\n",
       "  -0.9222099184989929,\n",
       "  0.9999514222145081,\n",
       "  -0.2804638743400574,\n",
       "  -0.974888265132904,\n",
       "  0.9992789626121521,\n",
       "  -0.9999714493751526,\n",
       "  -0.9999977946281433,\n",
       "  -0.9977434277534485,\n",
       "  -1.0,\n",
       "  -0.9835903644561768,\n",
       "  -0.9999945163726807,\n",
       "  -0.9999674558639526,\n",
       "  -0.9130510091781616,\n",
       "  0.9999872446060181,\n",
       "  -0.39764857292175293,\n",
       "  -0.9992930293083191,\n",
       "  -0.9998430013656616,\n",
       "  0.5310957431793213,\n",
       "  -0.9404956698417664,\n",
       "  -0.650137186050415,\n",
       "  -1.0,\n",
       "  -0.24477499723434448,\n",
       "  1.0,\n",
       "  0.5303425788879395,\n",
       "  0.6159261465072632,\n",
       "  -0.9999622702598572,\n",
       "  0.9550118446350098,\n",
       "  -0.9994868040084839,\n",
       "  -0.8761022686958313,\n",
       "  0.9999842047691345,\n",
       "  0.9999968409538269,\n",
       "  0.9990549087524414,\n",
       "  0.995032787322998,\n",
       "  -0.9990866184234619,\n",
       "  -0.9878762364387512,\n",
       "  0.9984807968139648,\n",
       "  0.9992800951004028,\n",
       "  0.9997925162315369,\n",
       "  -0.7199997305870056,\n",
       "  -0.9999915361404419,\n",
       "  0.27021461725234985,\n",
       "  0.9999979138374329,\n",
       "  -0.9956304430961609,\n",
       "  -0.9999998807907104,\n",
       "  0.9992889165878296,\n",
       "  -0.9931018948554993,\n",
       "  0.9999996423721313,\n",
       "  0.9999974966049194,\n",
       "  0.9970600008964539,\n",
       "  0.7636435627937317,\n",
       "  0.24923504889011383,\n",
       "  0.9976241588592529,\n",
       "  -0.9999987483024597,\n",
       "  -0.47703346610069275,\n",
       "  -0.9999880194664001,\n",
       "  1.0,\n",
       "  0.7559309005737305,\n",
       "  -0.9999725222587585,\n",
       "  -0.9999901056289673,\n",
       "  -0.9796570539474487,\n",
       "  -0.9999903440475464,\n",
       "  -0.8328922390937805,\n",
       "  -0.999634325504303,\n",
       "  0.9999718070030212,\n",
       "  -0.9999997019767761,\n",
       "  -0.7009108066558838,\n",
       "  0.9999982714653015,\n",
       "  -0.9999439716339111,\n",
       "  -0.7958822846412659,\n",
       "  0.8320109844207764,\n",
       "  0.9991364479064941,\n",
       "  -1.0,\n",
       "  -0.9999945759773254,\n",
       "  0.41609588265419006,\n",
       "  -0.9955074787139893,\n",
       "  0.999874472618103,\n",
       "  0.9826291799545288,\n",
       "  0.9866594672203064,\n",
       "  0.9999998211860657,\n",
       "  0.9999876618385315,\n",
       "  -0.9773608446121216,\n",
       "  0.5750702023506165,\n",
       "  0.9954397082328796,\n",
       "  0.9999579191207886,\n",
       "  -0.9906917214393616,\n",
       "  0.9990525841712952,\n",
       "  -0.9973344206809998,\n",
       "  0.9999914765357971,\n",
       "  0.9976105690002441,\n",
       "  0.9859640598297119,\n",
       "  -0.9769059419631958,\n",
       "  -0.9446991682052612,\n",
       "  -0.9999971985816956,\n",
       "  -0.9999997615814209,\n",
       "  0.9999994039535522,\n",
       "  0.9998224377632141,\n",
       "  -0.9994728565216064,\n",
       "  -0.9950333833694458,\n",
       "  0.9548154473304749,\n",
       "  1.0,\n",
       "  -0.8797428011894226,\n",
       "  -0.9979642033576965,\n",
       "  0.9995211362838745,\n",
       "  1.0,\n",
       "  0.999915361404419,\n",
       "  0.9999303817749023,\n",
       "  -0.986506998538971,\n",
       "  -0.9950563311576843,\n",
       "  0.9891979694366455,\n",
       "  -0.9645187854766846,\n",
       "  0.8403620719909668,\n",
       "  -1.0,\n",
       "  0.9807268381118774,\n",
       "  -0.9747490882873535,\n",
       "  0.9969861507415771,\n",
       "  0.9996926188468933,\n",
       "  0.521499752998352,\n",
       "  0.9999546408653259,\n",
       "  1.0,\n",
       "  0.9975482821464539,\n",
       "  0.3493693768978119,\n",
       "  -0.9408075213432312,\n",
       "  -0.9848994612693787,\n",
       "  0.9999991059303284,\n",
       "  0.9999986886978149,\n",
       "  0.9996723532676697,\n",
       "  0.9998769760131836,\n",
       "  -0.9134387969970703,\n",
       "  -1.0,\n",
       "  0.9746704697608948,\n",
       "  -0.7196570634841919,\n",
       "  0.9706289172172546,\n",
       "  0.9999999403953552,\n",
       "  0.987764835357666,\n",
       "  -0.9999974370002747,\n",
       "  -0.9999720454216003,\n",
       "  0.302410751581192,\n",
       "  0.9996621608734131,\n",
       "  0.9962711334228516,\n",
       "  -0.9922471642494202,\n",
       "  0.9999954104423523,\n",
       "  1.0,\n",
       "  -1.0,\n",
       "  -0.09162464737892151,\n",
       "  -1.0,\n",
       "  0.9989571571350098,\n",
       "  -0.043970584869384766,\n",
       "  -0.9999627470970154,\n",
       "  1.0,\n",
       "  0.9935245513916016,\n",
       "  0.995844841003418,\n",
       "  1.0,\n",
       "  -0.9974619150161743,\n",
       "  0.9988872408866882,\n",
       "  -0.9901053309440613,\n",
       "  -0.9995347261428833,\n",
       "  0.9999986290931702,\n",
       "  -0.9997025728225708,\n",
       "  0.9999253153800964,\n",
       "  -0.4356449246406555,\n",
       "  0.99943608045578,\n",
       "  0.9993577599525452,\n",
       "  0.9442524909973145,\n",
       "  0.9904565215110779,\n",
       "  0.9999993443489075,\n",
       "  -0.999702513217926,\n",
       "  -0.998415470123291,\n",
       "  -0.9957821369171143,\n",
       "  0.9999998211860657,\n",
       "  -0.671367347240448,\n",
       "  0.9960029125213623,\n",
       "  -0.9968059659004211,\n",
       "  -0.9999995827674866,\n",
       "  -0.9994470477104187,\n",
       "  0.9999910593032837,\n",
       "  0.9999874830245972,\n",
       "  -0.9999997019767761,\n",
       "  0.9999908804893494,\n",
       "  -0.9951553344726562,\n",
       "  0.3934879004955292,\n",
       "  0.9987305402755737,\n",
       "  0.998256504535675,\n",
       "  -0.9995288252830505,\n",
       "  0.9820500016212463,\n",
       "  0.9902275204658508,\n",
       "  0.7407785654067993,\n",
       "  0.9949837923049927,\n",
       "  -0.9121967554092407,\n",
       "  1.0,\n",
       "  -0.7470605373382568,\n",
       "  -0.9782114028930664,\n",
       "  0.9999995231628418,\n",
       "  -0.9997835755348206,\n",
       "  -0.9923783540725708,\n",
       "  -0.9999942779541016,\n",
       "  -0.7962192893028259,\n",
       "  0.999998927116394,\n",
       "  0.997515082359314,\n",
       "  0.9999403953552246,\n",
       "  0.9999962449073792,\n",
       "  -0.9999780058860779,\n",
       "  -0.5222470760345459,\n",
       "  -0.9999966621398926,\n",
       "  0.9999998807907104,\n",
       "  0.9999922513961792,\n",
       "  -0.9977543950080872,\n",
       "  0.6346988677978516,\n",
       "  0.9994788765907288,\n",
       "  -0.05019460245966911,\n",
       "  0.9893428087234497,\n",
       "  0.9999948740005493,\n",
       "  0.9964742064476013,\n",
       "  0.9961764216423035,\n",
       "  -0.9993854761123657,\n",
       "  -0.9986874461174011,\n",
       "  -0.9831815361976624,\n",
       "  -0.9087438583374023,\n",
       "  -0.9343031644821167,\n",
       "  0.9971264004707336,\n",
       "  0.20328305661678314,\n",
       "  0.9395430684089661,\n",
       "  -0.6999027132987976,\n",
       "  -0.7511507868766785,\n",
       "  -0.9984282851219177,\n",
       "  0.9993659257888794,\n",
       "  0.9999983310699463,\n",
       "  -0.7132715582847595,\n",
       "  -0.9963781237602234,\n",
       "  0.9972250461578369,\n",
       "  0.9998613595962524,\n",
       "  -0.7047337889671326,\n",
       "  -0.9999969601631165,\n",
       "  0.24810326099395752,\n",
       "  -0.9873166680335999,\n",
       "  0.22199741005897522,\n",
       "  1.0,\n",
       "  -0.9607785940170288,\n",
       "  0.05196389555931091,\n",
       "  -0.9854405522346497,\n",
       "  0.9999419450759888,\n",
       "  0.943925142288208,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9996009469032288,\n",
       "  0.9999962449073792,\n",
       "  1.0,\n",
       "  0.9998196959495544,\n",
       "  -0.999979555606842,\n",
       "  -0.9999801516532898,\n",
       "  0.998870313167572,\n",
       "  -0.834336519241333,\n",
       "  -0.9711052179336548,\n",
       "  -0.9043070077896118,\n",
       "  0.41068753600120544,\n",
       "  -0.838234007358551,\n",
       "  -0.9127988219261169,\n",
       "  0.7615442276000977,\n",
       "  0.9999739527702332,\n",
       "  1.0,\n",
       "  0.999081552028656,\n",
       "  0.9999966621398926,\n",
       "  0.9978997707366943,\n",
       "  0.9597756862640381,\n",
       "  0.09858673065900803,\n",
       "  -0.9846727252006531,\n",
       "  0.9997222423553467,\n",
       "  1.0,\n",
       "  0.9643712639808655,\n",
       "  0.9962643980979919,\n",
       "  0.991788387298584,\n",
       "  1.0,\n",
       "  0.9963077902793884,\n",
       "  -0.9940040707588196,\n",
       "  1.0,\n",
       "  -0.9999576210975647,\n",
       "  0.9998401999473572,\n",
       "  -0.9999987483024597,\n",
       "  -0.9997629523277283,\n",
       "  -0.8682730197906494,\n",
       "  0.6903643012046814,\n",
       "  -1.0,\n",
       "  0.989473819732666,\n",
       "  0.9958595037460327,\n",
       "  -0.9995633959770203,\n",
       "  -0.7832342982292175,\n",
       "  0.9999671578407288,\n",
       "  -1.0,\n",
       "  -0.9760887026786804,\n",
       "  -0.9961367249488831,\n",
       "  -0.9999999403953552,\n",
       "  -1.0,\n",
       "  -0.9999998807907104,\n",
       "  0.0051240473985672,\n",
       "  -0.9945639371871948,\n",
       "  -0.9934664964675903,\n",
       "  -0.9356578588485718,\n",
       "  -0.9999848008155823,\n",
       "  0.9147899150848389,\n",
       "  0.9794678092002869,\n",
       "  -0.2974971830844879,\n",
       "  0.9999982714653015,\n",
       "  0.999993085861206,\n",
       "  -0.9869389533996582,\n",
       "  0.970585286617279,\n",
       "  0.9999008774757385,\n",
       "  0.9567596912384033,\n",
       "  -0.8896995186805725,\n",
       "  -0.39646002650260925,\n",
       "  -0.9999851584434509,\n",
       "  -0.9994198679924011,\n",
       "  0.9999923706054688,\n",
       "  0.9998577833175659,\n",
       "  1.0,\n",
       "  0.999999463558197,\n",
       "  -0.8073892593383789,\n",
       "  -0.9999308586120605,\n",
       "  0.9996596574783325,\n",
       "  -0.9215890765190125,\n",
       "  -0.364086776971817,\n",
       "  -0.9999755620956421,\n",
       "  -0.9999774694442749,\n",
       "  -0.49837031960487366,\n",
       "  0.6994414329528809,\n",
       "  -0.9999438524246216,\n",
       "  -0.9997803568840027,\n",
       "  0.9991251230239868,\n",
       "  0.9669179916381836,\n",
       "  0.9999998807907104,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9715888500213623,\n",
       "  -0.9998754858970642,\n",
       "  0.9942351579666138,\n",
       "  0.9990424513816833,\n",
       "  -0.9996504187583923,\n",
       "  0.9999974966049194,\n",
       "  0.9998712539672852,\n",
       "  0.5606979131698608,\n",
       "  -0.7505902051925659,\n",
       "  0.9999971985816956,\n",
       "  -0.9998314380645752,\n",
       "  0.9403150081634521,\n",
       "  -0.39404523372650146,\n",
       "  0.9999219179153442,\n",
       "  0.6005094647407532,\n",
       "  0.9930739402770996,\n",
       "  -1.0,\n",
       "  1.0,\n",
       "  -0.9999856948852539,\n",
       "  0.9931708574295044,\n",
       "  0.9999233484268188,\n",
       "  -0.9080142974853516,\n",
       "  0.9995772242546082,\n",
       "  -0.0849178209900856,\n",
       "  -0.9690039753913879,\n",
       "  0.9562427401542664,\n",
       "  -0.9981966018676758,\n",
       "  -0.7484919428825378,\n",
       "  -0.9999805688858032,\n",
       "  0.9960989952087402,\n",
       "  0.9999951720237732,\n",
       "  -0.9999837875366211,\n",
       "  -0.9691163897514343,\n",
       "  -0.9999955892562866,\n",
       "  0.9999868869781494,\n",
       "  0.9671062231063843,\n",
       "  -0.779212236404419,\n",
       "  -0.933711588382721,\n",
       "  -0.993659257888794,\n",
       "  0.9999024271965027,\n",
       "  -0.997288167476654,\n",
       "  -0.4752001166343689,\n",
       "  0.46161824464797974,\n",
       "  0.8195046782493591,\n",
       "  0.9844123721122742,\n",
       "  0.6601710319519043,\n",
       "  0.9969537854194641,\n",
       "  0.9999974370002747,\n",
       "  0.9999994039535522,\n",
       "  -0.345223069190979,\n",
       "  -0.657630205154419,\n",
       "  1.0,\n",
       "  -0.9999820590019226,\n",
       "  -0.9999999403953552,\n",
       "  0.9999564290046692,\n",
       "  -0.8079715371131897,\n",
       "  -0.841617226600647,\n",
       "  -0.993401050567627,\n",
       "  0.9968197345733643,\n",
       "  -0.9698160886764526,\n",
       "  -0.9644457101821899,\n",
       "  -0.9961028099060059,\n",
       "  0.9609130024909973,\n",
       "  0.9918834567070007,\n",
       "  -0.7623035311698914,\n",
       "  -0.9651315212249756,\n",
       "  -0.9997057914733887,\n",
       "  -0.9998828768730164,\n",
       "  -0.9823068976402283,\n",
       "  -0.5724990963935852,\n",
       "  0.9613929390907288,\n",
       "  -0.4925171136856079,\n",
       "  -0.9999995827674866,\n",
       "  -0.9118375778198242,\n",
       "  0.950928807258606,\n",
       "  0.2798527777194977,\n",
       "  -0.999107301235199,\n",
       "  0.9760763645172119,\n",
       "  -0.9999996423721313,\n",
       "  -0.04408706724643707,\n",
       "  -0.9991833567619324,\n",
       "  -0.9979013204574585,\n",
       "  -0.999039888381958,\n",
       "  0.999996542930603,\n",
       "  -0.7565717697143555,\n",
       "  0.46024295687675476,\n",
       "  0.9941437840461731,\n",
       "  -0.9431619048118591,\n",
       "  0.9993552565574646,\n",
       "  0.9996356964111328,\n",
       "  -0.9999986290931702,\n",
       "  -0.7378554344177246,\n",
       "  0.9015827178955078,\n",
       "  -0.99798983335495,\n",
       "  0.9999216198921204,\n",
       "  -0.9416670203208923,\n",
       "  -0.8336090445518494,\n",
       "  0.6840475797653198,\n",
       "  -0.9980457425117493,\n",
       "  1.0,\n",
       "  0.9988377094268799,\n",
       "  -0.4745528995990753,\n",
       "  0.9579533338546753,\n",
       "  -1.0,\n",
       "  -1.0,\n",
       "  0.9993125200271606,\n",
       "  0.9999632239341736,\n",
       "  0.7483908534049988,\n",
       "  -0.9890069365501404,\n",
       "  -0.6051065921783447,\n",
       "  -0.1817064881324768,\n",
       "  -0.45043492317199707,\n",
       "  0.9562357068061829,\n",
       "  0.9200424551963806,\n",
       "  0.9998474717140198,\n",
       "  0.9999961256980896,\n",
       "  0.9997398257255554,\n",
       "  0.601611852645874,\n",
       "  0.9987313747406006,\n",
       "  0.9018997550010681,\n",
       "  -0.7301973700523376,\n",
       "  -0.9999962449073792,\n",
       "  -0.999671220779419,\n",
       "  0.9886369109153748,\n",
       "  -0.9999673962593079,\n",
       "  1.0,\n",
       "  0.9947219491004944,\n",
       "  0.3413320779800415,\n",
       "  -0.005187926813960075,\n",
       "  0.9999997615814209,\n",
       "  0.674632728099823,\n",
       "  -0.3639845848083496,\n",
       "  0.969049334526062,\n",
       "  0.9870827794075012,\n",
       "  -0.9999589920043945,\n",
       "  -0.22613590955734253,\n",
       "  0.9999959468841553,\n",
       "  -0.9999569654464722,\n",
       "  0.9960743188858032,\n",
       "  -0.9197618961334229,\n",
       "  0.9999962449073792,\n",
       "  -0.9993183016777039,\n",
       "  -0.9341828227043152,\n",
       "  0.9999995231628418,\n",
       "  0.999370276927948,\n",
       "  0.9999995827674866,\n",
       "  -0.9999933838844299,\n",
       "  0.9842403531074524,\n",
       "  0.9720035195350647,\n",
       "  0.9999738931655884,\n",
       "  0.9927579164505005,\n",
       "  0.9633733630180359,\n",
       "  0.99931800365448,\n",
       "  0.9985504746437073,\n",
       "  0.023633012548089027,\n",
       "  0.9965823292732239,\n",
       "  -1.0,\n",
       "  0.9238299131393433,\n",
       "  0.9994993805885315,\n",
       "  -0.9962184429168701,\n",
       "  -0.9970365762710571,\n",
       "  -0.7447825074195862,\n",
       "  -0.9969920516014099,\n",
       "  -0.9999805688858032,\n",
       "  -0.461659699678421,\n",
       "  0.9943370819091797,\n",
       "  -0.9999995827674866,\n",
       "  -0.9936452507972717,\n",
       "  0.9226517677307129,\n",
       "  0.2630269527435303,\n",
       "  -0.7297932505607605,\n",
       "  -0.9972667694091797,\n",
       "  0.9999992847442627,\n",
       "  1.0,\n",
       "  0.9935709834098816,\n",
       "  0.9999993443489075,\n",
       "  0.9742825031280518,\n",
       "  -0.621557891368866,\n",
       "  -0.9923649430274963,\n",
       "  1.0,\n",
       "  0.9989307522773743,\n",
       "  -0.26416826248168945,\n",
       "  0.9999962449073792,\n",
       "  0.97966068983078,\n",
       "  0.721097469329834,\n",
       "  -0.6381284594535828,\n",
       "  -0.8915583491325378,\n",
       "  0.40349751710891724,\n",
       "  0.9999991059303284,\n",
       "  0.7616611123085022,\n",
       "  0.9997807145118713,\n",
       "  0.9950311779975891,\n",
       "  0.9999856948852539,\n",
       "  -0.9136130809783936,\n",
       "  0.5313969850540161,\n",
       "  0.9990641474723816,\n",
       "  0.9990935325622559,\n",
       "  0.996920645236969,\n",
       "  -0.9827965497970581,\n",
       "  0.991476833820343,\n",
       "  -0.7608608603477478,\n",
       "  -0.9999951720237732,\n",
       "  0.9999887347221375,\n",
       "  0.9723818898200989,\n",
       "  -1.0,\n",
       "  0.04062742739915848,\n",
       "  0.9995129108428955,\n",
       "  0.9999307990074158,\n",
       "  0.999830961227417,\n",
       "  -0.9938317537307739,\n",
       "  -0.8309956192970276,\n",
       "  0.9999995827674866,\n",
       "  -0.9997881650924683,\n",
       "  0.9331311583518982,\n",
       "  -0.9989826679229736,\n",
       "  0.8178621530532837,\n",
       "  -0.9998709559440613,\n",
       "  0.9968336820602417,\n",
       "  -0.4521487355232239,\n",
       "  0.987983763217926,\n",
       "  0.9983922243118286,\n",
       "  0.9999996423721313,\n",
       "  0.9996381998062134,\n",
       "  0.9999989867210388,\n",
       "  -0.34491726756095886,\n",
       "  -1.0,\n",
       "  0.9999995231628418,\n",
       "  -0.5721119046211243,\n",
       "  0.5975648760795593,\n",
       "  -0.9999942183494568,\n",
       "  0.999568521976471,\n",
       "  0.9999996423721313,\n",
       "  -0.9979686737060547,\n",
       "  0.955635666847229,\n",
       "  -0.9609215259552002,\n",
       "  ...])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stretch h out into a single python list by using .view()\n",
    "h.view(-1).shape, h.view(-1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "979efabf-5382-4e89-841b-92cebb3a3cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a histogram of all activation values\n",
    "plt.hist(h.view(-1).tolist(), 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534ecdc-a889-4d70-8fe0-f4a150ca25b6",
   "metadata": {},
   "source": [
    "Above, from the hidden layer weights that are passed through the activation function, tanh, we see too many values of -1 or 1. This is due to the fact that tanh is a hyberbolic function similar to a sigmoid and squashes all values between 1 and -1.\n",
    "\n",
    "Looking at the outputs of the hidden layer as a histogram, we see that most values are between -20 and 20. With tanh, anything above or below $\\pm{\\pi}$ (~3.1415 etc.) is effectively = 1 and therefore a significant proportion of values are being cropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dbb77970-df33-498f-a5e0-2149fc37c86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a histogram of all hidden layer outputs - preactivation\n",
    "plt.hist(hpreact.view(-1).tolist(), 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54795425-4cc1-4b58-9d7d-49929bc2416e",
   "metadata": {},
   "source": [
    "This is *bad* for backpropagation.\n",
    "\n",
    "From micrograd, we know that the tanh function and it's derivative are written as below:\n",
    "\n",
    "\n",
    "```python\n",
    "def tanh(self):\n",
    "    x = self.data\n",
    "    t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1) # tanh function\n",
    "    out = Value(t, (self, ), 'tanh')\n",
    "\n",
    "    def _backward(():\n",
    "        self.grad += (1 - t**2) * out.grad\n",
    "    out._backward = _backward\n",
    "\n",
    "    return out\n",
    "```\n",
    "\n",
    "The derivative of this function w.r.t the loss is $(1 - tanh^2(x)) * \\frac{dL}{dx}$ which means when $tanh(x)$ takes a value of -1 or 1, or equivalently $x$ takes a value of less than $-\\pi$ or $\\pi$, then the gradient is evaluated at 0 and backpropogration stops there. \n",
    "\n",
    "Since backpropagation computes the gradient of the loss function with respect to the model parameters by applying the chain rule through each layer, a zero gradient at any layer will cause the gradient of earlier layers to be zero as well. This can prevent updates to certain parameters during training.\n",
    "\n",
    "This means that we can be changing these parameters however we want, but due to this 0 gradient, it will have no impact on the loss since the tanh function will render all subsequent updates up the network 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7777a333-376d-4abd-8874-a28a181e65e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11e669450>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(h.abs() > 0.99, cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fb26ea-3572-4148-ac0d-db34d259d1b4",
   "metadata": {},
   "source": [
    "Above we see this problem visually for our hidden layer of size 32x200. Every white square here will cause the gradients to be 0 and the neurons to be shut-off.\n",
    "\n",
    "If all examples land in the 'tail' of the tanh function, if there is a column of 'white' i.e. 0 gradients in the image above, this is a ***dead neuron*** that will not learn no matter what the inputs are. But, this doesn't quite seem to be the case here.\n",
    "\n",
    "This is a problem with most activation functions that have a flat tail. In the below images, leaky ReLU doesn't suffer from this problem.\n",
    "\n",
    "![hello](activation_functions.png \"Activation functions\")\n",
    "\n",
    "How do we fix this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3f5952-b857-4082-ae2f-0187b8c004d3",
   "metadata": {},
   "source": [
    "The problem lies in the lines below:\n",
    "\n",
    "```python\n",
    "emb = C[Xb]\n",
    "embcat = emb.view(emb.shape[0], -1)\n",
    "hpreact = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "```\n",
    "\n",
    "Since here `hpreact` values are too large, we need to ensure the initialsed weights of `W1` and `b1` aren't too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8b95b806-6f78-499d-869e-014963032471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11897\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator = g) * 0.1 # Multiply by 0.1 to ensure the pre-activations are closer to 0\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.01 # Okay to set biases to a very small number - allows for some diversity that can help\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.01\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d19d818f-c5c0-400e-9f54-3d80b91485c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3069\n"
     ]
    }
   ],
   "source": [
    "# use the same optimisation values as previously when building the MLP\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):#\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors by indexing (using X values) into the appropriate vector embeddings from the initialised C matrix\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if 1 < 100000 else 0.01 # step func for learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every 10k steps\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "\n",
    "    lossi.append(loss.log10().item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "742a4159-0513-460e-95a0-32d6ea97ff79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a histogram of all activation values\n",
    "plt.hist(h.view(-1).tolist(), 50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9e0f05a8-4246-44df-940c-c4ee950c16fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11e5269e0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(h.abs() > 0.99, cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c09c7e6-8cd6-4b36-80b0-9b8d6433402c",
   "metadata": {},
   "source": [
    "We now see that this has resulted in not a single white square. Not a single neuron weight has been clipped here since all values post-activation in `h` are within -1 and 1.\n",
    "\n",
    "We can afford to increase this slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "628f0927-0436-4136-a7a5-219d52b6cde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11897\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator = g) * 0.2 # Increase init weight slightly\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.01 \n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.01\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "73e5c2da-d9d3-4d17-8f01-c1fc46b87d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3135\n"
     ]
    }
   ],
   "source": [
    "# use the same optimisation values as previously when building the MLP\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):#\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors by indexing (using X values) into the appropriate vector embeddings from the initialised C matrix\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if 1 < 100000 else 0.01 # step func for learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every 10k steps\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "\n",
    "    lossi.append(loss.log10().item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "43d9ef26-8dfd-4ece-82bc-78412dfeaa7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11e5f0b80>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(h.abs() > 0.99, cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8124670a-35d1-4e32-bb89-86d65038b8d7",
   "metadata": {},
   "source": [
    "Now there are some that are being clipped by tanh, which is a better distribution.\n",
    "\n",
    "Let's run the full training loop again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b5e87426-b619-47af-b0ef-364680ecda37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.2465\n",
      "  10000/ 200000: 1.9043\n",
      "  20000/ 200000: 1.9004\n",
      "  30000/ 200000: 1.9465\n",
      "  40000/ 200000: 2.1656\n",
      "  50000/ 200000: 2.0071\n",
      "  60000/ 200000: 2.0826\n",
      "  70000/ 200000: 2.4228\n",
      "  80000/ 200000: 2.3109\n",
      "  90000/ 200000: 2.1167\n",
      " 100000/ 200000: 2.2166\n",
      " 110000/ 200000: 1.9169\n",
      " 120000/ 200000: 2.3950\n",
      " 130000/ 200000: 2.1029\n",
      " 140000/ 200000: 1.9980\n",
      " 150000/ 200000: 2.4943\n",
      " 160000/ 200000: 2.2493\n",
      " 170000/ 200000: 1.7603\n",
      " 180000/ 200000: 2.0242\n",
      " 190000/ 200000: 2.0386\n"
     ]
    }
   ],
   "source": [
    "# use the same optimisation values as previously when building the MLP\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):#\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors by indexing (using X values) into the appropriate vector embeddings from the initialised C matrix\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if 1 < 100000 else 0.01 # step func for learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every 10k steps\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "\n",
    "    lossi.append(loss.log10().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "77c03372-4526-44db-adfb-d15d360dde2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.1146562099456787\n",
      "val 2.1880691051483154\n"
     ]
    }
   ],
   "source": [
    "no_tanh_saturation_train_loss = split_loss('train')\n",
    "no_tanh_saturation_saturated_val_loss = split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fdb4dc96-8826-41fd-95cd-51c1ac7504fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "train:  2.1853060722351074\n",
      "val:  2.2459235191345215\n",
      "\n",
      "After fixing softmax being confidently wrong (better initialisation weights)\n",
      "train:  2.157895088195801\n",
      "val:  2.2293787002563477\n",
      "\n",
      "After fixing tanh being too saturated at init\n",
      "train:  2.1146562099456787\n",
      "val:  2.1880691051483154\n"
     ]
    }
   ],
   "source": [
    "# Loss log\n",
    "\n",
    "print('Original')\n",
    "print('train: ', starting_train_loss)\n",
    "print('val: ', starting_val_loss)\n",
    "\n",
    "\n",
    "print('\\nAfter fixing softmax being confidently wrong (better initialisation weights)')\n",
    "print('train: ', better_initialisation_train_loss)\n",
    "print('val: ', better_initialisation_val_loss)\n",
    "\n",
    "\n",
    "print('\\nAfter fixing tanh being too saturated at init')\n",
    "print('train: ', no_tanh_saturation_train_loss)\n",
    "print('val: ', no_tanh_saturation_saturated_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ab5623-c5b8-4809-96c0-2d273ed19191",
   "metadata": {},
   "source": [
    "## Utilising the Kaiming normalisation method\n",
    "\n",
    "From [Kaiming He et al 2015](https://arxiv.org/pdf/1502.01852)\n",
    "\n",
    "Instead of using \"magic numbers\" like 0.2 or 0.01 to scale down our initialisation weights, we can use more principled techniques to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3f5c3330-e246-4406-8a26-a4e289905f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0236) tensor(1.0048)\n",
      "tensor(-0.0006) tensor(0.6391)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.randn(1000, 10)\n",
    "w = torch.randn(10, 200) # Neurons in this hidden layer have 10 inputs and there are 200 neurons\n",
    "y = x @ w\n",
    "\n",
    "print(x.mean(), x.std())\n",
    "print(y.mean(), y.std())\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(121)\n",
    "plt.hist(x.view(-1).tolist(), 50, density=True);\n",
    "plt.subplot(122)\n",
    "plt.hist(y.view(-1).tolist(), 50, density=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e27252b-579d-4692-808f-8fd98085ace9",
   "metadata": {},
   "source": [
    "Above we input a tensor of size 1000x10 with a normal gaussian distribution of mean 0 and unit std. The same is true for the weights.\n",
    "\n",
    "When multiplying these tensors, we get `y` with the same mean but a std 3x larger ~3. We don't want this as we want all activations to be relatively similar in a NN. \n",
    "\n",
    "Multiplying the weights `w` by an integer value >1 will scale the y std by the same amount i.e. w * 5 = y.std() ~= 15. The same in conversely true, w * 0.2 = y.std() ~= 0.64.\n",
    "\n",
    "What is the correct term to multiply this by so that `y` has unit std? When worked out mathematically with the variances, `w` should be divided by the ***square root of the $fan_{in}$***. In this case the $fan_{in}$ = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "673b56f1-9d57-4c41-8caf-e344536a3188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0121) tensor(0.9957)\n",
      "tensor(-0.0007) tensor(1.0075)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.randn(1000, 10)\n",
    "w = torch.randn(10, 200) / (10**0.5) # Initialised by dividing by the square root of fan_in\n",
    "y = x @ w\n",
    "\n",
    "print(x.mean(), x.std())\n",
    "print(y.mean(), y.std())\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(121)\n",
    "plt.hist(x.view(-1).tolist(), 50, density=True);\n",
    "plt.subplot(122)\n",
    "plt.hist(y.view(-1).tolist(), 50, density=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b966a0b0-9cae-4609-bb94-07e1f1d04fe2",
   "metadata": {},
   "source": [
    "This produces a `y` tensor of unit std which is what we want for our layers in our NN. This is because it prevents the graidents from getting too large or too small and thereby prevents veanishing or exploding gradients.  \n",
    "\n",
    "In [Kaiming He et al 2015](https://arxiv.org/pdf/1502.01852) they find that this can be applied to any activation function but works best for ReLU and PReLU. This requires compensation from a gain however. Since the ReLU is a squashing function that effectively discards the half of the distribution below 0, the gain needs to be $\\sqrt{2}$. \n",
    "\n",
    "![hi](kaiming_he_2025_fig_1.png \"Kaiming He et al figure 1\")\n",
    "\n",
    "Therefore, the weights should be initialised as a Gaussian with mean 0 and std of:\n",
    "\n",
    "$\\sqrt{\\frac{2}{n_L}}$, where $n_L$ is the **fan_in**.\n",
    "\n",
    "As above this is done by dividing the weights by this factor. The difference is that we are initialising the weights by dividing by $\\sqrt{\\frac{1}{n_L}}$.\n",
    "\n",
    "Kaiming initialisation is also implemented in PyTorch, called the [Kaiming normal](https://docs.pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_normal_) and is the most common way of initialising neural networks now. It requires a few kwargs, the \"mode\" either fan_in or fan_out (in the paper this doesn't matter too much so we can leave this as fan_in) and the non-linearity activation function, advised to leave as ReLU or Leaky ReLU but this determines what gain should be used. Other activation functions require different gains and the calculation is implemented in the [torch.nn.init.calculate_gain function](https://docs.pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_normal_).\n",
    "\n",
    "**Why do we need a gain?** Since activation functions are a contractive operation, so in order to fight against this contraction we need to boost the weights slightly so that we get back to unit mean and std.\n",
    "\n",
    "Many modern innovations like residual connections, normalisation layers (group, layer, batch) and better optimisers like RMSProp and Adam make it less important to get this exactly correct. In practice, usually dividing by root fan_in is fine. \n",
    "\n",
    "Now let's apply this to our MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e27d73d3-c895-4be1-b04a-8075c46f7aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11897\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator = g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.01 \n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.01\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "23898a25-f7da-4068-84d5-010ba317d54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3179\n",
      "  10000/ 200000: 2.1910\n",
      "  20000/ 200000: 2.3270\n",
      "  30000/ 200000: 2.5396\n",
      "  40000/ 200000: 1.9468\n",
      "  50000/ 200000: 2.3331\n",
      "  60000/ 200000: 2.3852\n",
      "  70000/ 200000: 2.1173\n",
      "  80000/ 200000: 2.3159\n",
      "  90000/ 200000: 2.2010\n",
      " 100000/ 200000: 1.8591\n",
      " 110000/ 200000: 2.3167\n",
      " 120000/ 200000: 1.9626\n",
      " 130000/ 200000: 2.2936\n",
      " 140000/ 200000: 2.1852\n",
      " 150000/ 200000: 2.2831\n",
      " 160000/ 200000: 1.7577\n",
      " 170000/ 200000: 1.7677\n",
      " 180000/ 200000: 2.1656\n",
      " 190000/ 200000: 1.9137\n"
     ]
    }
   ],
   "source": [
    "# use the same optimisation values as previously when building the MLP\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):#\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors by indexing (using X values) into the appropriate vector embeddings from the initialised C matrix\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if 1 < 100000 else 0.01 # step func for learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every 10k steps\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "\n",
    "    lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "60404e92-032b-4d31-8164-2fee20021168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.1495206356048584\n",
      "val 2.2231829166412354\n"
     ]
    }
   ],
   "source": [
    "using_kaiming_init_train_loss = split_loss('train')\n",
    "using_kaiming_init_val_loss = split_loss('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d44394-e744-4333-9a1b-0d756f04aed6",
   "metadata": {},
   "source": [
    "## Batch normalisation\n",
    "\n",
    "Since we want our pre-activation states to be Gaussian, batch normalisation directly normalises the weights of the neurons to be Gaussian for each mini-batch. Original paper: https://arxiv.org/pdf/1502.03167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b05b786d-de04-493e-b73c-afea284c97fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 200])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpreact.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "376d3b15-330d-4e48-808e-b2cc78921de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpreact.mean(0, keepdims=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7b6aa96c-1735-41b6-b3d8-e6d676f61ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpreact.std(0, keepdims=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3cc92130-7134-40dc-ba70-0dd17516e86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator = g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.01 \n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.01\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0\n",
    "\n",
    "# Learnable gain and bias values for each neuron\n",
    "bngain = torch.ones((1, n_hidden))\n",
    "bnbias = torch.ones((1, n_hidden))\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ef0c04f5-9eb3-4169-b8d7-5a4c701399b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3401\n",
      "  10000/ 200000: 2.2846\n",
      "  20000/ 200000: 2.3284\n",
      "  30000/ 200000: 2.5253\n",
      "  40000/ 200000: 1.9592\n",
      "  50000/ 200000: 2.5090\n",
      "  60000/ 200000: 2.3124\n",
      "  70000/ 200000: 2.0885\n",
      "  80000/ 200000: 2.3997\n",
      "  90000/ 200000: 2.1687\n",
      " 100000/ 200000: 1.9234\n",
      " 110000/ 200000: 2.5179\n",
      " 120000/ 200000: 1.9902\n",
      " 130000/ 200000: 2.4860\n",
      " 140000/ 200000: 2.4409\n",
      " 150000/ 200000: 2.3410\n",
      " 160000/ 200000: 1.9847\n",
      " 170000/ 200000: 1.9724\n",
      " 180000/ 200000: 2.0784\n",
      " 190000/ 200000: 1.8786\n"
     ]
    }
   ],
   "source": [
    "# use the same optimisation values as previously when building the MLP\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):#\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] \n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1 # hidden layer pre-activation \n",
    "\n",
    "    # Batch normalisation layer:\n",
    "    # Utilises new trainable gain and bias parameters that are trained along with the network weights\n",
    "    hpreact = bngain * (hpreact - hpreact.mean(0, keepdims=True)) / hpreact.std(0, keepdims=True) + bnbias\n",
    "    \n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if 1 < 100000 else 0.01 # step func for learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every 10k steps\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "\n",
    "    lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "41042485-0566-45de-a58d-6359268a3df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # disables gradient tracking for a function\n",
    "def split_loss(split):\n",
    "    \"\"\"evaluate loss for a particular split of the data\"\"\"\n",
    "    x,y = {\n",
    "        'train': (Xtr, Ytr),\n",
    "        'val': (Xdev, Ydev),\n",
    "        'test': (Xte, Yte),\n",
    "    }[split]\n",
    "\n",
    "    emb = C[x]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "\n",
    "    # Add Batch norm layer for forward pass of train and test as well\n",
    "    hpreact = bngain * (hpreact - hpreact.mean(0, keepdims=True)) / hpreact.std(0, keepdims=True) + bnbias\n",
    "    h = torch.tanh(hpreact)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "956f355f-aabb-40a0-a703-d338add2830f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.1234352588653564\n",
      "val 2.1714096069335938\n"
     ]
    }
   ],
   "source": [
    "using_batch_norm_train_loss = split_loss('train')\n",
    "using_batch_norm_val_loss = split_loss('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0166fc35-464a-4504-81de-b363a1900a87",
   "metadata": {},
   "source": [
    "For a single hidden layer here, we don't expect much of an improvement but batch normalisation helps with the stability of the network during training when we have a deeper architecture. \n",
    "\n",
    "It does come at a significant cost however...\n",
    "\n",
    "Due to the sampling of minibatches - the mean and std of hpreact differs for each minibatch and depends on the other samples within the minibatch. This means that `h` jitters during training.\n",
    "\n",
    "This however does have a data augmentation effect in training and means that this actually _aids_ training. This works similarly to a regulariser. This can introduce bugs as this couples h to the examples in a batch. We have tried to get away from this property by introducing other normalisation techniques like layer norm etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a647bb-546e-4f36-ae07-fb6397fb526f",
   "metadata": {},
   "source": [
    "**This also now affects inference**\n",
    "\n",
    "Since during training, the batch norm layers now expect batches instead of single samples in order to calculate the mean and std of `hpreact`. We therefore need to calculate the batch norm statistics once and use those for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1b6fa196-6af9-4503-a5d9-69e0f7d2145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training\n",
    "\n",
    "with torch.no_grad():\n",
    "    emb = C[Xtr]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    # measure the mean/std over the entire training set\n",
    "    bnmean = hpreact.mean(0, keepdim=True)\n",
    "    bnstd = hpreact.std(0, keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d7648d56-2ffe-431a-a9f8-95a5bcb9444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # disables gradient tracking for a function\n",
    "def split_loss(split):\n",
    "    \"\"\"evaluate loss for a particular split of the data\"\"\"\n",
    "    x,y = {\n",
    "        'train': (Xtr, Ytr),\n",
    "        'val': (Xdev, Ydev),\n",
    "        'test': (Xte, Yte),\n",
    "    }[split]\n",
    "\n",
    "    emb = C[x]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "\n",
    "    # Add Batch norm layer for forward pass of train and test as well\n",
    "    hpreact = bngain * (hpreact - bnmean) / bnstd + bnbias\n",
    "    h = torch.tanh(hpreact)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c9327557-bb97-4201-af13-a18ed8100970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.1234352588653564\n",
      "val 2.171652317047119\n"
     ]
    }
   ],
   "source": [
    "using_batch_norm_train_loss = split_loss('train')\n",
    "using_batch_norm_val_loss = split_loss('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad1461e-071f-48c7-956f-3c019140d9e3",
   "metadata": {},
   "source": [
    "However, this requires a separate stage to calculate these statistics for each layer after training. A more efficient manner to do this would be to calculate this in a running manner during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8e604e1c-a382-4472-a34e-d256fdef09f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator = g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.01 \n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.01\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0\n",
    "\n",
    "# Learnable gain and bias values for each neuron\n",
    "bngain = torch.ones((1, n_hidden))\n",
    "bnbias = torch.ones((1, n_hidden))\n",
    "# Initialise the mean and std for each hidden layer neuron at 0 for mean and 1 for std\n",
    "# These do not have gradients calculated for them and their primary purpose is to stabilise training\n",
    "# As such we keep track of them on the side of training\n",
    "bnmean_running = torch.zeros((1, n_hidden))\n",
    "bnstd_running = torch.ones((1, n_hidden))\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ffddb1c7-40c8-4fc7-a21b-85f0dacb555e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3401\n",
      "  10000/ 200000: 2.2846\n",
      "  20000/ 200000: 2.3284\n",
      "  30000/ 200000: 2.5253\n",
      "  40000/ 200000: 1.9592\n",
      "  50000/ 200000: 2.5090\n",
      "  60000/ 200000: 2.3124\n",
      "  70000/ 200000: 2.0885\n",
      "  80000/ 200000: 2.3997\n",
      "  90000/ 200000: 2.1687\n",
      " 100000/ 200000: 1.9234\n",
      " 110000/ 200000: 2.5179\n",
      " 120000/ 200000: 1.9902\n",
      " 130000/ 200000: 2.4860\n",
      " 140000/ 200000: 2.4409\n",
      " 150000/ 200000: 2.3410\n",
      " 160000/ 200000: 1.9847\n",
      " 170000/ 200000: 1.9724\n",
      " 180000/ 200000: 2.0784\n",
      " 190000/ 200000: 1.8786\n"
     ]
    }
   ],
   "source": [
    "# use the same optimisation values as previously when building the MLP\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):#\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] \n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1 # hidden layer pre-activation \n",
    "\n",
    "    # Batch normalisation layer:\n",
    "    # Utilises new trainable gain and bias parameters that are trained along with the network weights\n",
    "    bnmeani = hpreact.mean(0, keepdims=True)\n",
    "    bnstdi = hpreact.std(0, keepdims=True)\n",
    "    hpreact = bngain * (hpreact - bnmeani) / bnstdi + bnbias\n",
    "\n",
    "    # Update the running mean and std with small incremental updates every epoch\n",
    "    # This isn't included in the backward pass at all since it's on the side of training\n",
    "    # We just want to nudge the mean and std in the direction of the mean and std\n",
    "    # of the current mini-batch\n",
    "    # In this way we don't need a secondary stage to calculate these values ready for inference\n",
    "    # This is the same way that this is calculated in PyTorch\n",
    "    with torch.no_grad():\n",
    "        bnmean_running = bnmean_running * 0.999 + 0.001 * bnmeani\n",
    "        bnstd_running = bnstd_running * 0.999 + 0.001 * bnstdi\n",
    "    \n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if 1 < 100000 else 0.01 # step func for learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every 10k steps\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "\n",
    "    lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d5ea76-95f4-4088-8118-6baba6364864",
   "metadata": {},
   "source": [
    "So we can check whether the running mean and std are close to the post-calculated mean and std. Generally they are fairly similar and we can now use this in the inference for the train and val sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "baaff774-80ce-4a9c-8ac9-f66ba24c0a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch norm mean vs running mean within 0.1: True\n",
      "Batch norm std vs running std within 0.1: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch norm mean vs running mean within 0.1:\", torch.allclose(bnmean, bnmean_running, atol=0.1))\n",
    "print(\"Batch norm std vs running std within 0.1:\", torch.allclose(bnstd, bnstd_running, atol=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5c878ab4-d5a7-488c-80d1-1fc5828ddf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # disables gradient tracking for a function\n",
    "def split_loss(split):\n",
    "    \"\"\"evaluate loss for a particular split of the data\"\"\"\n",
    "    x,y = {\n",
    "        'train': (Xtr, Ytr),\n",
    "        'val': (Xdev, Ydev),\n",
    "        'test': (Xte, Yte),\n",
    "    }[split]\n",
    "\n",
    "    emb = C[x]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "\n",
    "    # Use bnmean and bnstd running here\n",
    "    hpreact = bngain * (hpreact - bnmean_running) / bnstd_running + bnbias\n",
    "    h = torch.tanh(hpreact)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "278e2566-77ee-4bb8-abff-0ea60c7baa08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.126382350921631\n",
      "val 2.1754138469696045\n"
     ]
    }
   ],
   "source": [
    "using_batch_norm_train_loss = split_loss('train')\n",
    "using_batch_norm_val_loss = split_loss('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23fc9a9-9de2-42d7-b1a6-6b9188c192d3",
   "metadata": {},
   "source": [
    "We see that the val and train loss are very similar to before. So we have eliminated the need for a separate calibration step post-training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1583fd-b845-4230-81e8-b07133cb52fd",
   "metadata": {},
   "source": [
    "### Batch Norm - Note 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc0242e-4838-4953-bbd7-a76874cae949",
   "metadata": {},
   "source": [
    "In the original paper, we notice an $\\epsilon$ term during the normalisation stage given by the formula below:\n",
    "\n",
    "$$\\hat{x_i} \\leftarrow \\frac{x_i - \\mu_{\\mathcal{B}}^2}{\\sqrt{\\sigma_{\\mathcal{B}}^2 - \\epsilon}}$$\n",
    "\n",
    "This term is a very small addition (usually 1e-5 etc.) to avoid division by 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b366b70-66b8-4082-81aa-d3e41a0c47fa",
   "metadata": {},
   "source": [
    "### Batch Norm - Note 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b303d6-b97f-4932-bb83-5e7d1f056834",
   "metadata": {},
   "source": [
    "For our implementation of Batch Norm now, the bias term is effectively being cancelled out due to the batch norm layer.\n",
    "\n",
    "```python\n",
    "hpreact = embcat @ W1 + b1 # b1 is cancelled out due to hpreact - bnmeani below\n",
    "bnmeani = hpreact.mean(0, keepdims=True)\n",
    "bnstdi = hpreact.std(0, keepdims=True)\n",
    "hpreact = bngain * (hpreact - bnmeani) / bnstdi + bnbias\n",
    "```\n",
    "\n",
    "Therefore, since `b1` is being subtracted out, it doesn't impact the rest of the calculation. This means `b1.grad` is 0. Whenever a batch norm layer is being used, if there is a weight layer before it, it's better to not use a bias. Instead, this is being handled by the `bnbias` which is now in charge of biasing the layer distribution. The job of the bias is generally to shift the weights to the left or right and allow the network to better fit the distribution of the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181f2b43-c84c-4579-9a63-03e0756d954d",
   "metadata": {},
   "source": [
    "### Batch Norm - Summary:\n",
    "\n",
    "Batch normalisation is used to **control the statistics of activations** in a neural network. This avoids saturation of neurons when they take extreme values in the hidden layer and leads to the **dead neuron** problem where neurons get stuck in a sturated state (-1 or 1 for tanh). Any input will cause these neurons to have the same output which effectively means they stop learning. \n",
    "\n",
    "It's common to spirinkle Batch Norm layers throughout the neural net and usually it is added after layers that have multiplcations, for example linear or convolutional layers. The batch norm layer itself has parameters that will be learned during training in backprop, these are the **gain** and the **bias**. It also has 2 buffers, the running **mean** and **standard deviation**, these are not trained using backprop but are instead nudged towards the population mean and stdev. \n",
    "\n",
    "Effectively, batch norm is calculating the mean and std of the activations that is feeding into the batch norm layer over a single batch, then it centres the batch to be unit Gaussian, then scaling it by the learned bias and gain. On top of that it's keeping track of the mean and std of the inputs and maintaining a running mean and std that can be used at inference time. This avoids needing a batch of inference samples and allows feeding in a single example at a time that is not dependent on the mean and std of the inference batch samples - stabilising it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e9afd6-55ba-47c6-ac5c-5ce0b9992357",
   "metadata": {},
   "source": [
    "Final training loop with Batch Norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f079222c-c03d-4b2a-996a-8f76d6ce1507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 2.4029\n",
      "  10000/ 200000: 1.8153\n",
      "  20000/ 200000: 2.4769\n",
      "  30000/ 200000: 2.5702\n",
      "  40000/ 200000: 2.2104\n",
      "  50000/ 200000: 2.3212\n",
      "  60000/ 200000: 2.1664\n",
      "  70000/ 200000: 1.7232\n",
      "  80000/ 200000: 2.2377\n",
      "  90000/ 200000: 2.3878\n",
      " 100000/ 200000: 1.8324\n",
      " 110000/ 200000: 2.0116\n",
      " 120000/ 200000: 2.2182\n",
      " 130000/ 200000: 2.4150\n",
      " 140000/ 200000: 2.1520\n",
      " 150000/ 200000: 2.3550\n",
      " 160000/ 200000: 2.2134\n",
      " 170000/ 200000: 2.1852\n",
      " 180000/ 200000: 2.0512\n",
      " 190000/ 200000: 2.2625\n"
     ]
    }
   ],
   "source": [
    "# use the same optimisation values as previously when building the MLP\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors for the context/window size by viewing the tensor as a different shape\n",
    "    # Linear layer\n",
    "    hpreact = embcat @ W1 #+ b1 # hidden layer pre-activation - no need for b1 bias due to being superceded by batch norm bias\n",
    "\n",
    "    # Batch normalisation layer:\n",
    "    # ---------------------------------------------------------------\n",
    "    bnmeani = hpreact.mean(0, keepdims=True)\n",
    "    bnstdi = hpreact.std(0, keepdims=True)\n",
    "    hpreact = bngain * (hpreact - bnmeani) / bnstdi + bnbias\n",
    "\n",
    "    with torch.no_grad():\n",
    "        bnmean_running = bnmean_running * 0.999 + 0.001 * bnmeani\n",
    "        bnstd_running = bnstd_running * 0.999 + 0.001 * bnstdi\n",
    "    # ---------------------------------------------------------------\n",
    "    # Activation (allowing the network to learn non-linearity in the training data)\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if 1 < 100000 else 0.01 # step func for learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every 10k steps\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "\n",
    "    lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ee2c6f6d-7c52-40ec-a10e-303670ec121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.1125400066375732\n",
      "val 2.1671502590179443\n"
     ]
    }
   ],
   "source": [
    "using_batch_norm_train_loss = split_loss('train')\n",
    "using_batch_norm_val_loss = split_loss('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaea60e-9eeb-4b6d-9b41-ab6e22cbf139",
   "metadata": {},
   "source": [
    "## Real example: ResNet-50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c06aff4-52e7-40c3-87ee-ee549864eb92",
   "metadata": {},
   "source": [
    "The resnet-50 architecture has a repeating layer block called the Bottleneck that uses a pattern of convolutional layer, batch norm and activation. The PyTorch implementation is linked [here](https://docs.pytorch.org/vision/master/_modules/torchvision/models/resnet.html) and the forward pass is provided below:\n",
    "\n",
    "```python\n",
    "def forward(self, x: Tensor) -> Tensor:\n",
    "    identity = x\n",
    "\n",
    "    out = self.conv1(x)\n",
    "    out = self.bn1(out)\n",
    "    out = self.relu(out)\n",
    "\n",
    "    out = self.conv2(out)\n",
    "    out = self.bn2(out)\n",
    "    out = self.relu(out)\n",
    "\n",
    "    out = self.conv3(out)\n",
    "    out = self.bn3(out)\n",
    "\n",
    "    if self.downsample is not None:\n",
    "        identity = self.downsample(x)\n",
    "\n",
    "    out += identity\n",
    "    out = self.relu(out)\n",
    "\n",
    "    return out\n",
    "```\n",
    "\n",
    "Note here that there is no bias defined with the conv1 layer since this is handled in the batch norm layer as previously explained. The [PyTorch implementation of the linear layer](https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html) allows the bias to be set to `False` if your layer is followed by a batch norm layer.\n",
    "\n",
    "```python\n",
    "class torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)\n",
    "```\n",
    "This linear layer contains 2 variables, a weight and a bias, the same as what we've defined above.\n",
    "\n",
    "> Variables:\n",
    "> \n",
    "> weight (torch.Tensor) - the learnable weights of the module of shape (out_features, in_features). The values are initialized from $U(-sqrt(k), sqrt(k))$, where $k = \\frac{1}{in\\_features}$.\n",
    "> \n",
    "> bias - the learnable bias of the module of shape (out_features). If `bias` is `True`, the values are initialized from $U(-sqrt(k), sqrt(k))$, where $k = \\frac{1}{in\\_features}$.\n",
    "\n",
    "where in_features = fan_in, U = Uniform distn, gain = 1\n",
    "\n",
    "The reason PyTorch is scaling by $(-sqrt(k), sqrt(k))$ is due to the fact that if you have a roughly Gaussian input, scaling by this in a Unirform dist will produce a roughly Gaussian output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706a7e10-44f7-4f33-a6ea-4c73f0eb5d4d",
   "metadata": {},
   "source": [
    "#### Now onto the Batch Norm layer\n",
    "\n",
    "Link: https://docs.pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html\n",
    "\n",
    "In this implementation the `num_features` kwarg is the same as the `n_hidden` dimension in our implementation above. We also need to define the `momentum` which is the same as the running mean and std factor we utilise above. By default this is 0.1 in PyTorch, however, we are using 0.001 above. Generally, momentum should be set in accordance with your batch size, if you have a larger batch size, the mean and std will be roughly the same, so you can use a higher value of momentum. For our mini-batches of size 32, this will be jumping around which means we need to use a smaller momentum.\n",
    "\n",
    "`affine` is a boolean that determines whether we should train the learnable parameters from our batch norm layer - in our case, bngain and bnbias. This should always be set to True. \n",
    "\n",
    "`track_running_stats` determines whether BtachNorm should calculate the running mean and std. This can be set to False if this is done in post-training.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acb8891-03de-4884-8ed4-59a1c34008a4",
   "metadata": {},
   "source": [
    "# PyTorch-ifying our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1ebf98-cf76-46b6-8357-435fde32304c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
